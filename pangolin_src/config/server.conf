[ _ ]
# labs: SFTP synchronisation
# (except in case of abnormally slow operation, sync can be left active)
skipsync=
# labs: sample sorting and import
# (set to 0 for labs whose sequences we aren't currently importing, e.g. due to problems)
declare -A lab
lab=( ['gfb']=0 ['fgcz']=1 ['h2030']=0 ['viollier']=0 )
# NOTE: h2030 isn't sequencing as the number of cases is lower.
# pass '--force' to force overwriting any existing file when moving
sort_force=--force
# base wastewater dir
wwdir=/app
# base directory
basedir=${wwdir}/workdir
# sub-directory of openbis download for rights fixing
download=openbis-downloads
# sub-directory containing the scripts
scriptdir=${wwdir}/pangolin_src
# directory containing the entire git repository, for logging purposes
codebase=${wwdir}/codebase
# sub-directory to hold the sorted samples set
# working sub-directory
# linking instead of copying ?
#  --reflink for CoW filesystems (ZFS, BTRFS)
#  --hardlink for most unix-like filesystems
link=--link
# Installation directory of miniconda3
baseconda=${wwdir}/miniconda3
# File containing the Rsync password
rsync_pass=/home/bs-pangolin/.ssh/rsync.pass.euler
# YAML file containing the primers
protocolyaml=references/primers.yaml
# Regular expression to recognize sample names
rxsample='(^[[:digit:]]{6,}_)|(^[[:digit:]]{8,})|(^Y[[:digit:]]{8,})|([[:digit:]]{2}_20[[:digit:]]{2}_[01]?[[:digit:]]_[0-3]?[[:digit:]])|(^KLZHC[oO][vV])|(^B[aA][[:digit:]]{4,})|(^USB_20[[:digit:]]{2}_[01]?[[:digit:]]_[[:digit:]]{2}_.{8})'

# group on the storage (inside download and sampleset)
# storgrp=bsse-covid19-pangolin@d.ethz.ch
storgrp=bs-pangolin-group
# parallel copy jobs
parallel=8
# parallel backup copy jobs
parallelpull=4
# whereto push the sequences at the end
#releasedir=/links/shared/covid19-pangolin/pangolin/consensus_data/batch/
#releasedir=$(realpath $(pwd)/batch)
# timeout before rsync considers the transfer failed in seconds
rsynctimeout=2000
# SSH connection timeout
contimeout=300
# IO timeout
iotimeout=300
# suspend jobs submission in case of problems
donotsubmit=0
# skip or run ShoRAH step of V-pipe
run_shorah=0
# mail
mailfrom='Automation-carillon<bs-pangolin@ethz.ch>'
mailto=
# timeout for the whole automation loop
runtimeout=7200
# timeout to wait for 'sync' command: 0: no timeout, "": default, otherwise seconds
synctimeout=0
# directory containing the local copy of the dataset
local_dataset=/app/dataset

# Cluster config
# username used on the cluster (while we're switching over)
cluster_user=bs-pangolin
cluster=euler.ethz.ch
clusterdir="/cluster/project/pangolin/test_automation/pangolin/pangolin_src"
clusterdir_old="/cluster/project/pangolin"
working=working
sampleset="sampleset"
# rsyncd module to sync from the remote status folder
remote_status=remote_status
# rsyncd module to sync from the remote bfabric sync folder
bfabric_downloads=bfabric-downloads
# rsyncd module to sync to the remote VILOCA work folder
work_viloca=work-viloca
#rsyncd module to sync to the remote uploader work folder
#work_uploader=work-uploader
# Directory containing the git repository of V-pipe
vpipe_code=/cluster/project/pangolin/V-pipe

# BSSE folder backups config
# Do we want to backup the Vpipe results?
backup_vpipe=1
# Do we want to backup the VILOCA results?
backup_viloca=0
# Do we want to backup the uploader results?
backup_uploader=1
# Do we want to backup the FGCZ mirror?
backup_fgcz_raw=1
# Do we want to backup the amplicon coverage results?
backup_amplicon_cov=1
# the user of the remote machine used for backup
bck_user=bs-pangolin
# the hostname of the remote machine used for backup
bckhost=d@bs-bewi08
# Remote directory for the uploader results
remote_uploader_backup_dir=/links/shared/covid19-pangolin/backup/uploader_results

# VILOCA-specific configuration
run_viloca=0
donotsubmit_viloca=0
# Local VILOCA work directory
viloca_basedir=${basedir}/viloca
# Remote VILOCA base directory
remote_viloca_basedir=${clusterdir_old}/work-viloca
# Remote processing directory for VILOCA
viloca_processing=SARS-CoV-2-wastewater-sample-processing-VILOCA
# Remote results subdirectory for VILOCA
viloca_results=results
# Name of the sample list file for VILOCA
viloca_samples=samples.csv
# Staging file for VILOCA sample list
viloca_staging=${viloca_samples}.staging

# Upload-specific configuration
# Do we run the uploader section at all, including adding new samples to the list?
run_uploader=1
# Location of the sendCrypt executable for the uploads
sendcrypt_exec=${HOME}/.sendcrypt/sendcrypt
# Do we submit the data to upload? A "1" means that the uploader will only update the list
donotsubmit_uploader=0
# Clean sendcrypt temporary directories
clean_sendcrypt_temp=1
# Filename of the list of samples to upload
uploaderlist=batches_to_upload.tsv
# Remote work directory for the uploader
uploader_workdir=${basedir}/uploader
# Directory containing the samples to be uploaded
uploader_dataset=/app/dataset
# Directory containing the sampleset files of the samples to upload
uploader_sampleset=${basedir}/tmp/belfrysheets/
# Number of samples to upload every try
uploader_sample_number=100
# Daily quota of files to upload on SPSP
upload_number_quota=1000000000000
# Daily quota of size to upload on SPSP in MB
upload_size_quota=500000
# Average expected size in MB of an sample to upload
upload_avg_size=500
# Remote folder containing the uploader code
uploader_code=${wwdir}/uploader
# Remote temporary directory for files that should be dropped or overwritten between runs
uploader_tempdir=${uploader_workdir}/temp
# Remote sub directory of the staging directory where the files to upload should be copied
uploader_target=${uploader_tempdir}/target
# Remote archival directory for the upload files
uploader_archive=/app/dataset/archive
# Remote location of the full list of uploaded samples
uploader_uploaded=${uploader_workdir}/all_uploaded.tsv
# Do we check for updates for sendcrypt every time the uploader runs?
update_sendcrypt=1

# Amplicon coverage-specific configuration
run_amplicon_coverage=1
remote_amplicon_coverage_workdir=${clusterdir_old}/work-amplicon-coverage
remote_amplicon_coverage_code=${remote_amplicon_coverage_workdir}/amplicon_cov
remote_primers_bed=${remote_amplicon_coverage_code}/ArticV531primers.bed
remote_amplicon_coverage_tempdir=${remote_amplicon_coverage_workdir}/temp

# Status tracking configuration
statusdir=${basedir}/status
viloca_statusdir=${statusdir}/viloca
uploader_statusdir=${statusdir}/uploader
lockfile=${statusdir}/carillon_lock
# statusfile containing the number of uploaded files for the day
uploader_number_status=${uploader_statusdir}/uploader_number
amplicon_coverage_statusdir=${statusdir}/amplicon_coverage
