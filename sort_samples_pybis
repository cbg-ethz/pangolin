#!/usr/bin/env python3

import io
import sys
import atexit
import os
import re
import math
import netrc
import configparser
import argparse
import yaml
from pybis import Openbis
from pybis import __version__ as pybisver
from dateutil import parser

# progress bar unicode
def bar(v, m=128):
    f = v & 7
    return (
        ("\u2588" * (v >> 3))
        + (chr(0x2590 - f) if f else "")
        + ("\u00b7" * ((m - v) >> 3))
    )


# parse command line
argparser = argparse.ArgumentParser(
    description="Fetch metadata from OpenBIS server using PyBIS APIs"
)
argparser.add_argument(
    "-c",
    "--config",
    metavar="CONF",
    required=False,
    default="server.conf",
    type=str,
    dest="config",
    help="configuration file to load",
)
argparser.add_argument(
    "-q",
    "--skipqc",
    required=False,
    action="store_true",
    dest="skipqc",
    help="Do not require presence of FastQC files",
)
argparser.add_argument(
    "-f",
    "--force",
    required=False,
    action="store_true",
    dest="force",
    help="Force overwriting any existing file when moving",
)
argparser.add_argument(
    "-s",
    "--summary",
    required=False,
    action="store_true",
    dest="summary",
    help="Only display a summary of datasets, not an exhaustive list of all samples",
)
argparser.add_argument(
    "-r",
    "--recent",
    metavar="ONLYAFTER",
    required=False,
    dest="recent",
    help="Only process datasets (runs) whose date-based ID is posterior to the argument",
)
args = argparser.parse_args()


# Load defaults from config file
config = configparser.ConfigParser(
    strict=False
)  # non-strict: support repeated section headers
config.SECTCRE = re.compile(
    r"\[ *(?P<header>[^]]+?) *\]"
)  # support spaces in section headers
with open(args.config) as f:
    config.read_string(
        f"""
[DEFAULT]
lab={os.path.splitext(os.path.basename(args.config))[0]}
samtype=ILLUMINA_FLOW_LANE
basedir={os.getcwd()}
sampleset=sampleset
download=openbis-downloads
link=--link
mode=
[_]
"""
        + f.read()
    )  # add defaults + a pseudo-section "_" right before the ini file, to support bash-style section_header-less config files

lab = config["_"]["lab"].strip("\"'")
"""name of the lab, to put in the batch YAML"""
fileserver = config["_"]["fileserver"].strip("\"'")
"""name of the _SFTP_ server, as used when fetching data files (i.e.: same name as in netrc file)"""
apiurl = config["_"]["apiurl"].strip("\"'")
"""address of the _Web_ server whose API we are calling"""
expname = config["_"]["expname"].strip("\"'")
"""experiment name in OpenBIS"""
samtype = config["_"]["samtype"].strip("\"'")
"""the type for which need to search the experiment thourgh"""
basedir = config["_"]["basedir"].strip("\"'")
"""base dircetory"""
download = config["_"]["download"].strip("\"'")
"""sub-directory to hold the unsorted downloaded datasets"""
sampleset = config["_"]["sampleset"].strip("\"'")
"""sub-directory to hold the sorted samples set"""
link = config["_"]["link"].strip("\"'")
"""
linking instead of copying ?
 --reflink for CoW filesystems (ZFS, BTRFS)
 --hardlink for most unix-like filesystems
"""

# parse the chmod parameter
try:
    cf_mode = config["_"]["mode"].strip("\"'")
    mkdirmode = int(cf_mode, base=8) if cf_mode else None
except:
    print(
        f"cannot parse <{config['_']['mode']}> as an octal chmod value. see `mkdir --help` for informations"
    )
    sys.exit(2)

# Hardcoded tables
suffix = {"ONE": "_MM_1", "NONE": ""}

# RegEx to parse some specific string
rxrun = re.compile(
    "(?ms)Run type: (?P<type>\S+).*Number of cycles: (?P<len>\d+).*Run folder: (?P<run>(?P<date>\d{6})_[-\w]*)"
)  # e.g.: 'Run type: PAIRED_END\nNumber of cycles: 251\n\nKit : MS9275058-600V3\nRun folder: 200430_M01761_0414_000000000-J3JCT' or {...}'folder: 201023_A00730_0259_BHTVCCDRXX'
rxcell = re.compile(
    "(?<=/)(?P<seq>(?:\w+-)?(?P<cell>\w+)(?:\:(?P<lane>\d+))?)$"
)  # e.g.: '/BSSE_STADLER_COVID/000000000-CTT3D:1' or '/BSSE_STADLER_COVID/HTVCCDRXX:2'
rxclean = re.compile(
    "[\W_]+"
)  # or [\-\.\:\/] : characters that are converted to '_' for file-system friendliness
rxrecent = re.compile("^(?P<year>\d{4})(?:(?P<month>\d{2})(?P<day>\d{2})?)?")

samkwargs = {}
if args.recent:
    try:
        m = rxrecent.match(args.recent).groupdict()
    except:
        print(f"cannot parse recent <{args.recent}>")
    else:
        samkwargs[
            "registrationDate"
        ] = f">{m['year']}-{m['month'] if  m.get('month',None) else '01'}-{m['day'] if m.get('day',None) else '01'}"
        print(f"requesting registrationDate {samkwargs['registrationDate']}")


# create sampleset directory if missing
if not os.path.isdir(os.path.join(basedir, sampleset)):
    try:
        kwmkdir = {"mode": mkdirmode} if mkdirmode else {}
        os.mkdir(os.path.join(basedir, sampleset), **kwmkdir)
    except FileExistsError:
        pass

# we use ~/.netrc to obtain credentials
# (we need that config file anyway to download the data files from openbis' fileserver)
username, password = netrc.netrc().authenticators(fileserver)[0::2]

## console interactive
# import getpass
# username='ivan.topolsky@bsse.ethz.ch'
# password=getpass.getpass()

o = Openbis(apiurl, verify_certificates=True, use_cache=True)
o.login(
    username, password, save_token=True
)  # save the session token in ~/.pybis/example.com.token
atexit.register(o.logout)

# shell script file with all moving instructions inside
sh = open(os.path.join(basedir, sampleset, "movedatafiles.sh"), "wt")
print(
    r"""
link='%(link)s'
mode='%(mode)s' # e.g.: --mode=0770

# Helper
fail() {
	printf '\e[31;1mArgh: %%s\e[0m\n'	"$1"	1>&2
	[[ -n "$2" ]] && echo "$2" 1>&2
	exit 1
}

warn() {
	printf '\e[33;1mArgh: %%s\e[0m\n'	"$1"	1>&2
	[[ -n "$2" ]] && echo "$2" 1>&2
}

ALLOK=1
X() {
	ALLOK=0
}

cd %(basedir)s

# sanity checks
[[ -d '%(download)s' ]] || fail 'No download directory:' '%(download)s'
[[ -d '%(sampleset)s' ]] || fail 'No sampleset directory:' '%(sampleset)s'
"""
    % {
        "link": link,
        "mode": (f"--mode={mkdirmode:04o}" if mkdirmode else ""),
        "basedir": basedir,
        "download": download,
        "sampleset": sampleset,
    },
    file=sh,
)


# o.get_projects(space='BSSE_STADLER_COVID', code='STADLER_COVID')[0].get_experiments()
ex = o.get_experiment(code=expname)

if "1.18" <= pybisver <= "1.20.0":
    samkwargs["count"] = 10
samples = ex.get_samples(
    type=samtype, props={"data_transferred", "CONTAINER_PROPERTIES"}, **samkwargs
)
# HACK avoid extreme long waits on some buggy versions of PyBIS

# NOTE iterating over `samples` is problematic, use pandas dataframe instead
#  - in jupyter, it crashes with "TypeError: argument of type 'int' is not iterable"
#  - in plain python3, it takes ages (probably making server request on each constructor).
# for sa in samples:
# print("%s\t%s\t%s" % (sa.permId, sa.identifier, sa.p.data_transferred))

dataframe = samples.df
prgrs = 0
prgmax = len(dataframe)
status = 0
batchtsv = {}  # dictionary to hold output files per batches
batchlanes = {}  # dictionary to count lanes used in each batch
batchseensname = {}  # dictionary to check when samples are replicated accross lanes
# iterate through samples, i.e.: through flow cell lanes
for sa in dataframe.sort_values(by=["registrationDate"], ascending=[True]).itertuples(
    name="Sample"
):
    # parse the container properties for run type and read cycles count
    try:
        m = rxrun.search(sa.CONTAINER_PROPERTIES).groupdict()
    except:
        print(
            f"cannot parse: {sa.CONTAINER_PROPERTIES}\n{list(map(lambda x: '%x' % ord(x), sa.CONTAINER_PROPERTIES[0:4]))}"
        )
        m = {}
    runfolder = m.get("run", "")
    rlen = int(m["len"]) - 1 if "len" in m else ""
    rtype = m.get("type", "")
    rundate = (
        f"20{m['date']}" if "date" in m else None
    )  # NOTE runfolders are yymmdd, not yyyymmdd
    skip = False
    if args.recent:
        if sa.permId < args.recent:
            skip = True
    print(
        sa.permId,
        sa.identifier,
        sa.registrationDate,
        sa.DATA_TRANSFERRED,
        rtype,
        rlen,
        runfolder,
        ("skip" if skip else ""),
        sep="\t",
    )

    # progress bar
    barstr = bar(math.floor(prgrs * 128 / prgmax))
    print(f"\r[{barstr}] {prgrs}/{prgmax}", end=("\r" if args.summary else "\n"))
    print(f"echo -ne '\\r[{barstr}] {prgrs}/{prgmax} \\r'", file=sh)
    prgrs += 1

    if skip:
        prgmax -= 1
        prgrs -= 1
        continue

    lane = cell = seq = ""
    try:
        # get the sequencing name, and the flow cell name	original/000000000_CTTKK_1 or HTVCCDRXX_2
        m = rxcell.search(sa.identifier)
        cell = m.group("cell")
        seq = rxclean.sub(
            "_", m.group("seq")
        )  # clean-up seqname from unfriendly caracters
        # HACK original/000000000_CTTKK_1 or /000000000-JDWB9_1 depending on versions so we wildcard it
        seqdir = (
            m.group("seq").replace(":", "_")
            if sa.permId >= "20201209" or sa.permId == "20201123091827016-60728674"
            else seq
        )
        lane = int(m.group("lane"))
    except:
        print("!!! rx matching failed, cannot detect cell and lane")
        continue

    # batch: date + flow cell, e.g.: '20200426-J3JCY'
    regdate = parser.parse(sa.registrationDate).strftime("%Y%m%d")
    if rundate is None:  # fall back: registrationDate
        batch = f"{regdate}_{cell}"
    else:  # ideally, the run folder's date (first six digits)
        if regdate != rundate:
            print(f"\u001b[K\t!!! Batch mismatch: {rundate} vs {regdate}")
        batch = f"{rundate}_{cell}"

    # only process data which was transfered, we don't have access permission for the rest yet
    try:
        datasets = o.get_datasets(
            sample=sa.permId,
            props={
                "EXTERNAL_SAMPLE_NAME",
                "FASTQ_SAMPLE_CODE",
                "BARCODE",
                "INDEX2",
                "MISMATCH_IN_INDEX",
            },
            count=(400 if "1.18" <= pybisver <= "1.20.0" else None),
        ).df  # '*').df #
        # HACK avoid extreme long waits on some buggy versions of PyBIS
    except:
        print("\u001b[K\t(not accessible yet - cannot open)")
    else:
        # we at least expect to see:
        # - BCL2FASTQ_BASECALLSTATS stats
        # - FASTQ_GZ for unindexed
        # - at least several FASTQ_GZ for indexed samples
        # - FASTQC
        # the last two are required, we don't use the first two.
        skip = False
        if not "EXTERNAL_SAMPLE_NAME" in datasets.columns:
            print("\u001b[K\t(missing samplenames)", end="")
            if pybisver == "1.20.1":
                print(f"probaby a bug of PyBIS {pybisver}")
                print(datasets.columns)
            skip = True
        else:
            numsam = (
                (datasets["type"] == "FASTQ_GZ")
                & (datasets["EXTERNAL_SAMPLE_NAME"] != "")
            ).sum()
            if numsam < 1:  # we need at least 1 named sample
                print(f"\u001b[K\t(nsamples: {numsam})", end="")
                skip = True
        if not (datasets["type"] == "FASTQC").any():  # we need FASTQC to be present
            # print(datasets['type']=='FASTQC')
            print("\u001b[K\t(missing fastqc)", end="")
            if not args.skipqc:
                skip = True
        if skip:
            print("\t(not usable yet - skipping)")
            continue

        tsv = None
        fastqc = None
        dupecount = 0
        if batch in batchtsv:
            if lane in batchlanes[batch]:
                print(
                    f"\u001b[K\t!!! duplicate lane {lane} already seen in {batchlanes[batch][lane]}"
                )
            else:
                batchlanes[batch][lane] = sa.permId

            tsv = batchtsv[batch]
        else:
            # batch TSV sample list
            batchtsv[batch] = tsv = open(
                os.path.join(basedir, sampleset, f"samples.{batch}.tsv.staging"), "wt"
            )
            batchlanes[batch] = {lane: sa.permId}
            batchseensname[
                batch
            ] = (
                {}
            )  # check for duplicate samples in different lane (i.e.: fused samples)

            # batch YAML file with info
            # HACK this not the canonical way. we should be getting the parent of the current sa.permId, but every attempt thus far crashes
            # get the (non-empty) first sample fastq code among the datasets
            samdf = None
            for samcode in [
                c.replace("_", "-") for c in datasets["FASTQ_SAMPLE_CODE"] if c
            ]:
                samdf = ex.get_samples(code=samcode, props={"KIT"}).df
                if not samdf.shape[0]:
                    # move to the next one in succession until we have access
                    print(f"Can't access samplecode {samcode}", file=sys.stderr)
                    continue
                break

            libkit = samdf.KIT[0]
            if not args.summary:
                print("\t", samcode, libkit, sep="\t")

            with open(
                os.path.join(basedir, sampleset, f"batch.{batch}.yaml"), "wt"
            ) as yml:
                print(
                    yaml.dump(
                        {
                            "type": "openbis",
                            "lab": lab,
                            "url": apiurl,
                            "libkit": libkit,
                            "runfolder": runfolder,
                            "properties": sa.CONTAINER_PROPERTIES,
                        },
                        sort_keys=False,
                    ),
                    file=yml,
                )

        datasets["sname"] = datasets.apply(
            lambda ds: rxclean.sub("_", ds["EXTERNAL_SAMPLE_NAME"]), axis=1
        )  # clean-up samplename from un friendly caracter
        seensname = (
            {}
        )  # check for duplicate name in same lane (some crashes of OpenBIS cause this)
        # samples are sorted alphanumerically and FASTQC comes before all FASTQ_GZ
        for ds in datasets.sort_values(
            by=["type", "sname", "permId"], ascending=[True, True, False]
        ).itertuples(name="DataSets"):
            if not args.summary:
                print(
                    "\u001b[K\t",
                    ds.permId,
                    ds.type,
                    ds.status,
                    ds.registrationDate,
                    ds.sname,
                    ds.EXTERNAL_SAMPLE_NAME,
                    ds.FASTQ_SAMPLE_CODE,
                    ds.BARCODE,
                    ds.INDEX2,
                    ds.MISMATCH_IN_INDEX,
                    sep="\t",
                )
            # skip unavailable data files
            if ds.status == "AVAILABLE":
                # look for FASTQ files (skip undetermined indexes)
                if ds.type == "FASTQ_GZ" and ds.EXTERNAL_SAMPLE_NAME:
                    # check that we actually have a FastQC
                    if (fastqc is None) and (not args.skipqc):
                        print("No FASTQC", file=sys.stderr)
                        status |= 1
                    # upload error: duplicate samples (a typoe of OpenBIS crash).
                    if ds.sname in seensname:
                        # TODO sanity checks if it is indeed the same sample
                        print(
                            f"\u001b[K\t\tduplicate {ds.sname} already in {seensname[ds.sname]}",
                            file=sys.stderr,
                        )
                        continue
                    seensname[ds.sname] = ds.permId

                    # fusing multiple samples replicated in lanes
                    fusedupe = False
                    if ds.sname in batchseensname[batch]:
                        dupecount += 1
                        # print(f"{ds.sname} duplicate in lanes {lane} and {batchseensname[batch][ds.sname]}\n")
                        fusedupe = True
                    else:
                        print(ds.sname, batch, rlen, sep="\t", file=tsv)
                        batchseensname[batch][ds.sname] = lane
                    # 20200603125141062-60694758/original/BSSE_QGF_139661_000000000_CTTKK_1_MM_1/BSSE_QGF_139661_000000000_CTTKK_1_120000_239_D1_AAGTCGTG_AATTATGC_S97_L001_R1_001_MM_1.fastq.gz
                    print(
                        r"""
[[ -d '%(download)s/%(id)s' ]] || fail 'Not a directory:' '%(download)s/%(id)s (for %(sname)s)'
fastq=( %(download)s/%(id)s/original/%(fqcode)s_%(seq)s%(mm)s/%(fqcode)s_%(seq)s_%(sname)s_%(idx1)s_%(idx2)s_S*_L%(lane)03u_R[1-2]_*%(mm)s.fastq.gz )
[[ "${fastq[*]}" =~ [\*\[] ]] && fail 'Cannot list fastq files:' '%(id)s : %(sname)s'
(( ${#fastq[@]} != 2 )) && fail 'Number of fastq files not 2' "${#fastq[@]} : ${fastq[*]}"
mkdir ${mode} -p "%(sampleset)s/"{,"%(sname)s/"{,"%(batch)s/"{,raw_data,extracted_data}}}
for file in "${fastq[@]}"; do
	filename="${file##*/}"
	[[ $file =~ _L%(lane)03u_R[[:digit:]](_[[:digit:]]+%(mm)s.fastq.gz)$ ]] && destname="${filename//${BASH_REMATCH[1]}/.fastq.gz}"
	cp -v%(force)s ${link} "${file}" "%(sampleset)s/%(sname)s/%(batch)s/raw_data/${destname}"||X
	fqcname="${filename//%(mm)s.fastq.gz/_fastqc.html}"
	[[ $destname =~ _L%(lane)03u_(R[[:digit:]]).fastq.gz$ ]]"""
                        % {
                            "force": ("f" if args.force else ""),
                            "download": download,
                            "sampleset": sampleset,
                            "sname": ds.sname,
                            "batch": batch,
                            "id": ds.permId,
                            "fqcode": ds.FASTQ_SAMPLE_CODE,
                            "seq": seq,
                            "mm": (
                                suffix[ds.MISMATCH_IN_INDEX]
                                if ds.MISMATCH_IN_INDEX in suffix
                                else ""
                            ),
                            "idx1": ds.BARCODE,
                            "idx2": ds.INDEX2,
                            "lane": lane,
                        },
                        file=sh,
                    )
                    # copy FastQC only for none-dupes
                    if not fusedupe:
                        # HACK at this point, we might not know it's a fusedupe yet and do a copy we shouldn't
                        if fastqc is not None:
                            print(
                                r"""	cp %(force)s ${link} "%(download)s/%(fastqc)s/original/%(seqdir)s/${fqcname}" "%(sampleset)s/%(sname)s/%(batch)s/extracted_data/${BASH_REMATCH[1]}_fastqc.html"||X
done
"""
                                % {
                                    "force": ("-f" if args.force else ""),
                                    "download": download,
                                    "sampleset": sampleset,
                                    "sname": ds.sname,
                                    "batch": batch,
                                    "fastqc": fastqc,
                                    "seqdir": seqdir,
                                },
                                file=sh,
                            )
                    else:
                        # HACK remove any left over FastQC from the other copy, keep old dates to avoid re-updating
                        # TODO don't stream out movefile.sh but do proper two-step fusing as in bfabric_tsv
                        print(
                            r"""	rm -f "%(sampleset)s/%(sname)s/%(batch)s/extracted_data/${BASH_REMATCH[1]}_fastqc.html"
	touch --reference="%(sampleset)s/%(sname)s/%(batch)s/raw_data" "%(sampleset)s/%(sname)s/%(batch)s/extracted_data"
done
"""
                            % {
                                "sampleset": sampleset,
                                "sname": ds.sname,
                                "batch": batch,
                            },
                            file=sh,
                        )
                # look for FASTQC holder directory
                elif ds.type == "FASTQC":
                    # upload error: duplicate samples (a typoe of OpenBIS crash).
                    if fastqc is not None:
                        print(
                            f"\u001b[K\t\tduplicate FastQC already in {fastqc}",
                            file=sys.stderr,
                        )
                        continue
                    # 20200603132156916-60694852/original/000000000_CTTKK_1/BSSE_QGF_139567_000000000_CTTKK_1_120162_283_H2_AATGTTCT_AGTCACCT_S4_L001_R1_001_fastqc.html
                    fastqc = ds.permId  # keep the reference
        if dupecount:
            print(f"\u001b[K\t\t{dupecount} samples were duplicate from previous lane")

print(
    f"""
echo -e '\\r\\e[K[{bar(128)}] done.'
if (( !ALLOK )); then
	echo Some errors
	exit 1
fi;

""",
    file=sh,
)

# only in case of success: move staging files to final destination.
for b in batchtsv.keys():
    print(
        f"mv -v {sampleset}/samples.{b}.tsv.staging {sampleset}/samples.{b}.tsv",
        file=sh,
    )

print(
    """
echo All Ok
exit 0
""",
    file=sh,
)

if status == 1:
    sys.exit("Some FastQC files still missing")
