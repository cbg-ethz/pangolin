[general]
aligner = bwa
primers_trimmer = ivar
temp_prefix = /cluster/scratch/bs-pangolin/pangolin/temp
tsvbased=1
id_separator=/

[input]
datadir = samples/
#samples_file = samples.20210709_BPA73113-1417.tsv
#samples_file = samples.broken.tsv
samples_file = samples.catchup.tsv
#samples_file = ../working/samples.recent.tsv
#samples_file = samples.tsv
fastq_suffix =
reference = references/NC_045512.2.fasta
metainfo_file = references/metainfo.yaml
gff_directory = references/gffs/
primers_file = references/primers/v3/nCoV-2019.tsv
primers_bedfile = references/primers/v3/nCoV-2019.primer.bed
protocols_file = references/primers.yaml

[output]
datadir = samples/
cohortdir = ../variants/
trim_primers = True
snv = False
local = False
global = False
visualization = False
QA = True
dehumanized_raw_reads = True
upload = True


[preprocessing]
mem=4096

#
# Group: align
#

[sam2bam]
mem=5000

[ref_bwa_index]
mem=2000

[bwa_align]
#mem=2048
#mem=5120
mem=40690
#threads=6
threads=8
# linear scale breaks at 8~16 (See: https://www.researchgate.net/figure/Performance-of-Multi-Threading-CPU-time-and-walltime-usage-of-BWA-Mem-and-GATK_fig3_275950273)
#  2: 2739, 4: 5012, 6: 6045, 8: 6404 /8995

[bowtie_align]
#mem=2048
mem=12288
threads=6


[hmm_align]
leave_msa_temp = true



[consensus_sequences]
#conda=/cluster/project/pangolin/test/smallgenomeutilities.yaml

[frameshift_deletions_checks]
#conda=/cluster/project/pangolin/test/smallgenomeutilities.yaml
mem=8192
genes_gff=references/gffs/Genes_NC_045512.2.GFF3

[basecounts]

[coverage]
#conda=/cluster/project/pangolin/test/smallgenomeutilities.yaml
#mem=4096
#mem=256
mem=131072
threads=32
#threads=64
time=60

[minor_variants]
#mem=256
mem=16384
threads=64

[upload]
mem=256
time=10
threads=1
local=True
consensus=majority
options=-R

#
# Group: dehuman
#

[dehuman]
; mem=5120
; threads=12
#mem=4096
mem=65536
threads=16
time=540
ref_host = /cluster/project/igenomes/Homo_sapiens/NCBI/GRCh38/Sequence/BWAIndex/genome.fa
keep_host = true
catchup = true




#
# Group: SNV
#

[web_visualization]
# HACK mem_mb handling is inconsistent between snakemake's jobs.py (total) and profile LSF (per-job). Temporary lower mem to 1000MiB to avoid reserving 64x 2000MiB jobs' memory.
mem=1000

[coverage_intervals]
coverage=0
# HACK mem_mb do not exceed 1024MiB for now, see web_visualization
mem=1000
threads=1

[lofreq]
consensus=false

[snv]
consensus=false
#conda=/cluster/work/bewi/pangolin/test/shorah2.yaml
localscratch=$TMPDIR
### NOTE the next three parameters are going to be edited by a sed script
# as follows:	time	meme	threads
# - normal:	240	1024	64
# - hugemem:	1200	32768	63
time=240
#mem=1024
mem=65536
threads=64


#
# Divert to our local versions
#

[applications]
#extract_consensus=PYTHONPATH=/cluster/project/pangolin/test/smallgenomeutilities/ /cluster/project/pangolin/test/smallgenomeutilities/scripts/extract_consensus
#frameshift_deletions_checks=PYTHONPATH=/cluster/project/pangolin/test/smallgenomeutilities/ /cluster/project/pangolin/test/smallgenomeutilities/scripts/frameshift_deletions_checks
#gather_coverage=PYTHONPATH=/cluster/project/pangolin/test/smallgenomeutilities/ /cluster/project/pangolin/test/smallgenomeutilities/scripts/gather_coverage
#shorah=/cluster/work/bewi/pangolin/shorah-test/test/shorah-wrap shotgun -t 64
