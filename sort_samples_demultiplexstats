#!/usr/bin/env python3

import io
import sys
import os
import re
import json

import argparse

# parse command line
argparser = argparse.ArgumentParser(description="Uses bcl2fastq's demultiplexing stats as metadata to organise samples")
argparser.add_argument('-S', '--statsdir', metavar='DIR', required=True,
	type=str, dest='statsdir', help="directory containing 'Stats/Stats.json'")
argparser.add_argument('-f', '--fastqdir', metavar='DIR', required=False, default=None,
	type=str, dest='fastqdir', help="directory containing .fastq.gz files if different from above")
argparser.add_argument('-q', '--qcdir', metavar='DIR', required=False, default=None,
	type=str, dest='qcdir', help="if set, import FastQC's _fastqc.html files from there")
argparser.add_argument('-o', '--outdir', metavar='DIR', required=False, default='sampleset',
	type=str, dest='outdir', help="output directory")
argparser.add_argument('-s', '--summary', required=False,
	action='store_true', dest='summary', help="Only display a summary of datasets, not an exhaustive list of all samples")
argparser.add_argument('-a', '--append', required=False,
	action='store_true', dest='append', help="Append to the end of movedatafiles.sh, instead of overwritting\n(use when calling from an external combiner wrapper)")
argparser.add_argument('-n', '--noempty', required=False,
	action='store_true', dest='noempty', help="skip fastq.gz files with bad yield (0 reads)")
args = argparser.parse_args()

statsdir=args.statsdir
fastqdir=args.fastqdir if args.fastqdir else statsdir
qcdir=args.qcdir
sampleset=args.outdir
link='--link'
append=args.append
noempty=args.noempty

statsjson=os.path.join(statsdir, 'Stats/Stats.json')

# regex for parsing and/or validating strings
rxrun=re.compile('^(?P<date>\d{6})_(?P<instr>\w+)_(?P<num>\d+)_(?:(?:0+-)|[AB])(?P<cell>\w+)$') # e.g.: 200430_M01761_0414_000000000-J3JCT or 201023_A00730_0259_BHTVCCDRXX
rxcell=re.compile('(?:\w+-)?(?P<cell>\w+)$') # e.g.: '000000000-CTT3D' or 'HTVCCDRXX'


with open(statsjson, 'rt') as f:
	stats = json.loads(f.read());

# parse flowcell
try:
	m=rxcell.search(stats['Flowcell']).groupdict()
	flowcell=m['cell']
except:
	sys.exit(f"cannot parse: {stats['Flowcell']}")

# parse run folder
runfolder=stats['RunId']
try:
	m=rxrun.search(runfolder).groupdict()
	rundate=f"20{m['date']}" # NOTE runfolders are yymmdd, not yyyymmdd
	if flowcell != m['cell']:
		print(f"Warning: cell missmatch: {flowcell} vs {m['cell']}")
except:
	sys.exit(f"cannot parse: {runfolder}")

print(runfolder, flowcell, rundate, sep='\t')

# parse information about reads
lane={}
for l in stats['ReadInfosForLanes']: # lane
	lanenum=l['LaneNumber']
	ends=rlen=0
	for r in l['ReadInfos']: # read phases (indexes, reads)
		if r['IsIndexedRead']: continue 

		# sanity check
		if rlen and rlen != r['NumCycles']:
			print(f"Warning: read lenght changes from {rlen} to {r['NumCycles']} we currently only support symetric read lenghts")

		# gather info
		ends+=1
		if rlen < r['NumCycles']: rlen=r['NumCycles']
    
	# sanity check
	if ends < 1 or ends > 2:
		print(f"Error: we currently only support single or paired ends, but found {ends} reads")

	lane[lanenum]={'ends': ends, 'rlen': rlen-1}

# create sampleset directory if missing
if not os.path.isdir(sampleset):
	try:
		os.mkdir(sampleset, mode=0o770)
	except FileExistsError:
		pass

# output files
batch=f"{rundate}_{flowcell}"
tsv=open(os.path.join(sampleset,f'samples.{batch}.tsv'), 'wt')
# shell script file with all moving instructions inside
sh=open(os.path.join(sampleset,'movedatafiles.sh'), 'at' if append else 'wt')

# generic header: only for stand-alone files.
if not append: print(r'''
link='%(link)s'

# Helper
fail() {
	printf '\e[31;1mArgh: %%s\e[0m\n'	"$1"	1>&2
	[[ -n "$2" ]] && echo "$2" 1>&2
	exit 1
}

warn() {
	printf '\e[33;1mArgh: %%s\e[0m\n'	"$1"	1>&2
	[[ -n "$2" ]] && echo "$2" 1>&2
}

ALLOK=1
X() {
	ALLOK=0
}

# sanity checks
[[ -d '%(sampleset)s' ]] || fail 'No sampleset directory:' '%(sampleset)s'
''' % {'link':link,'sampleset':sampleset}, file=sh)

# per batch directory checks
print(r"[[ -d '%(download)s' ]] || fail 'No download directory:' '%(download)s'" % {'download':fastqdir}, file=sh)
if qcdir:
    print(r"[[ -d '%(qc)s' ]] || fail 'No download directory:' '%(qc)s'" % {'qc': qcdir}, file=sh)


# parse info about samples
for l in stats['ConversionResults']: # lane
	lanenum=l['LaneNumber']
	ends=lane[lanenum]['ends']
	rlen=lane[lanenum]['rlen']

	for s in l['DemuxResults']: # sample in lane
		samname=s['SampleName']

		# filter out fastq files with zero reads
		if noempty and s['NumberReads'] == 0:
			print(samname, "\x1b[33;1mBad yield !\x1b[0m", sep='\t')
			continue

		# info
		if not args.summary:
			print(samname, f"{'paired' if ends > 1 else 'single'}-end", rlen, sep='\t')
		# output files
		if tsv:
			print(samname, batch, rlen, sep='\t', file=tsv)
		if sh:
			subst={'download':fastqdir,'sampleset':sampleset,'sname':samname,'ends':ends,'batch':batch,'suffix':''}
			# 'midfix': _S*_L%(lane)03u
			# 'suffix': _001_MM_1 mm
			print(r'''
fastq=( %(download)s/%(sname)s*_R[1-2]*%(suffix)s.fastq.gz )
[[ "${fastq[*]}" =~ [\*\[] ]] && fail 'Cannot list fastq files:' '%(sname)s'
(( ${#fastq[@]} != %(ends)u )) && fail 'Number of fastq files not %(ends)u' "${#fastq[@]} : ${fastq[*]}"
mkdir --mode=0770 -p "%(sampleset)s/%(sname)s/%(batch)s/"{raw_data,extracted_data}
for file in "${fastq[@]}"; do
	filename="${file##*/}"
	[[ $file =~ _(R[[:digit:]])((_.*)?[.]fastq[.]gz)$ ]] && destname="${filename//${BASH_REMATCH[2]}/.fastq.gz}"
	cp -v ${link} "${file}" "%(sampleset)s/%(sname)s/%(batch)s/raw_data/${destname}"||X
''' % subst, file=sh)
		if qcdir:
			subst['fastqc']=qcdir
			print(r'''
	fqcname="${filename//%(suffix)s.fastq.gz/_fastqc.html}"
	cp -v ${link} "%(fastqc)s/${fqcname}" "%(sampleset)s/%(sname)s/%(batch)s/extracted_data/${BASH_REMATCH[1]}_fastqc.html"||X
''' % subst, file=sh)
			print('done', file=sh)


# coda: return status
if not append: print(f"""
if (( ALLOK )); then
	echo All Ok
	exit 0
else
	echo Some errors
	exit 1
fi;
""", file=sh)
